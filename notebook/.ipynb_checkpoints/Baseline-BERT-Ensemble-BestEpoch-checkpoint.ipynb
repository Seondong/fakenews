{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* https://www.kaggle.com/c/fake-news-pair-classification-challenge/data\n",
    "* https://github.com/fxsjy/jieba\n",
    "\n",
    "BERT\n",
    "* https://colab.research.google.com/github/tensorflow/tpu/blob/master/tools/colab/bert_finetuning_with_cloud_tpus.ipynb#scrollTo=Hcpfl4N2EdOk\n",
    "* https://github.com/google-research/bert/blob/master/multilingual.md\n",
    "\n",
    "Gluon-bert\n",
    "* https://gluon-nlp.mxnet.io/examples/sentence_embedding/bert.html\n",
    "\n",
    "Embedding options\n",
    "* https://github.com/Embedding/Chinese-Word-Vectors (Embedding 1)\n",
    "* https://github.com/facebookresearch/fastText/blob/master/docs/crawl-vectors.md (Embedding 2)\n",
    "\n",
    "Performance\n",
    "* Using Embedding 1: Performance 0.70640\n",
    "* Using Embedding 2: Performance 0.68641\n",
    "* Using BERT: Performance 0.849\n",
    "* Using BERT_WEIGHTED: Performance 0.85526\n",
    "* Using BERT_WEIGHTED+SameTID-Agreed: 0.85479\n",
    "    * Example: df_test[df_test.pred_label != df_test.pred_label2]인 아이들 다 agreed\n",
    "* Using BERT_WEIGHTED_train100: Performance 0.85634\n",
    "* Using BERT_ensemble_3models (cn, multi, uncased24): Performance 0.85619\n",
    "* Using BERT_ensemble_4models_weighted (cn, cnen, multi, uncased24): Performance 0.86283\n",
    "\n",
    "내일 submission: train / validation을 통해 epoch 최고값 잡고, 여러모델 최종값 merge "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/dmlab/sundong/competition/wsdm2019/fakenews/notebook/bert_repo\n"
     ]
    }
   ],
   "source": [
    "cd /home/dmlab/sundong/competition/wsdm2019/fakenews/notebook/bert_repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import modeling\n",
    "import optimization\n",
    "import run_classifier\n",
    "import tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/dmlab/sundong/competition/wsdm2019/fakenews/notebook\n"
     ]
    }
   ],
   "source": [
    "cd /home/dmlab/sundong/competition/wsdm2019/fakenews/notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"3,4,5\"\n",
    "\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "set_session(tf.Session(config=config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 9006529570799538627\n",
      ", name: \"/device:XLA_GPU:0\"\n",
      "device_type: \"XLA_GPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 6311215721989130790\n",
      "physical_device_desc: \"device: XLA_GPU device\"\n",
      ", name: \"/device:XLA_CPU:0\"\n",
      "device_type: \"XLA_CPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 1888509452451922134\n",
      "physical_device_desc: \"device: XLA_CPU device\"\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 15580053504\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 9860749503522972586\n",
      "physical_device_desc: \"device: 0, name: Tesla V100-SXM2-16GB, pci bus id: 0000:0b:00.0, compute capability: 7.0\"\n",
      ", name: \"/device:GPU:1\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 10762685645\n",
      "locality {\n",
      "  bus_id: 2\n",
      "  numa_node: 1\n",
      "  links {\n",
      "    link {\n",
      "      device_id: 2\n",
      "      type: \"StreamExecutor\"\n",
      "      strength: 1\n",
      "    }\n",
      "  }\n",
      "}\n",
      "incarnation: 9147351051863526064\n",
      "physical_device_desc: \"device: 1, name: Tesla V100-SXM2-16GB, pci bus id: 0000:85:00.0, compute capability: 7.0\"\n",
      ", name: \"/device:GPU:2\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 15580053504\n",
      "locality {\n",
      "  bus_id: 2\n",
      "  numa_node: 1\n",
      "  links {\n",
      "    link {\n",
      "      device_id: 1\n",
      "      type: \"StreamExecutor\"\n",
      "      strength: 1\n",
      "    }\n",
      "  }\n",
      "}\n",
      "incarnation: 15116942215282801968\n",
      "physical_device_desc: \"device: 2, name: Tesla V100-SXM2-16GB, pci bus id: 0000:86:00.0, compute capability: 7.0\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_fn_builder(features, seq_length, is_training, drop_remainder):\n",
    "    all_input_ids = []\n",
    "    all_input_mask = []\n",
    "    all_segment_ids = []\n",
    "    all_label_ids = []\n",
    "\n",
    "    for feature in features:\n",
    "        all_input_ids.append(feature.input_ids)\n",
    "        all_input_mask.append(feature.input_mask)\n",
    "        all_segment_ids.append(feature.segment_ids)\n",
    "        all_label_ids.append(feature.label_id)\n",
    "\n",
    "    def input_fn(params):\n",
    "\n",
    "        batch_size = 128\n",
    "\n",
    "        num_examples = len(features)\n",
    "\n",
    "        # This is for demo purposes and does NOT scale to large data sets. We do\n",
    "        # not use Dataset.from_generator() because that uses tf.py_func which is\n",
    "        # not TPU compatible. The right way to load data is with TFRecordReader.\n",
    "        d = tf.data.Dataset.from_tensor_slices({\n",
    "            \"input_ids\":\n",
    "                tf.constant(\n",
    "                    all_input_ids, shape=[num_examples, seq_length],\n",
    "                    dtype=tf.int32),\n",
    "            \"input_mask\":\n",
    "                tf.constant(\n",
    "                    all_input_mask,\n",
    "                    shape=[num_examples, seq_length],\n",
    "                    dtype=tf.int32),\n",
    "            \"segment_ids\":\n",
    "                tf.constant(\n",
    "                    all_segment_ids,\n",
    "                    shape=[num_examples, seq_length],\n",
    "                    dtype=tf.int32),\n",
    "            \"label_ids\":\n",
    "                tf.constant(all_label_ids, shape=[num_examples], dtype=tf.int32),\n",
    "        })\n",
    "\n",
    "        if is_training:\n",
    "            d = d.repeat()\n",
    "            d = d.shuffle(buffer_size=100)\n",
    "\n",
    "        d = d.batch(batch_size=batch_size, drop_remainder=drop_remainder)\n",
    "        return d\n",
    "\n",
    "    return input_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/dmlab/sundong/competition/wsdm2019/fakenews/notebook/results_chinese_L-12_H-768_A-12',\n",
       " '/home/dmlab/sundong/competition/wsdm2019/fakenews/notebook/results_multi_cased_L-12_H-768_A-12',\n",
       " '/home/dmlab/sundong/competition/wsdm2019/fakenews/notebook/results_uncased_L-24_H-1024_A-16']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BERT_MODEL_LIST = ['chinese_L-12_H-768_A-12', 'multi_cased_L-12_H-768_A-12', 'uncased_L-24_H-1024_A-16']\n",
    "['/home/dmlab/sundong/competition/wsdm2019/fakenews/notebook/results_'+model for model in BERT_MODEL_LIST]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** BERT pretrained directory: ../data/chinese_L-12_H-768_A-12 *****\n",
      "***** Model output directory: /home/dmlab/sundong/competition/wsdm2019/fakenews/notebook/results_optimized_chinese_L-12_H-768_A-12 *****\n",
      "WARNING:tensorflow:Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7f1bc37b62f0>) includes params argument, but params are not passed to Estimator.\n",
      "INFO:tensorflow:Using config: {'_model_dir': '/home/dmlab/sundong/competition/wsdm2019/fakenews/notebook/results_optimized_chinese_L-12_H-768_A-12', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 1000, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': None, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f1bc2d329b0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1, '_tpu_config': TPUConfig(iterations_per_loop=1000, num_shards=8, num_cores_per_replica=None, per_host_input_for_training=3, tpu_job_name=None, initial_infeed_sleep_secs=None, input_partition_dims=None), '_cluster': None}\n",
      "INFO:tensorflow:_TPUContext: eval_on_tpu True\n",
      "WARNING:tensorflow:eval_on_tpu ignored because use_tpu is False.\n",
      "Feature generating with train data\n",
      "INFO:tensorflow:Writing example 0 of 256442\n",
      "INFO:tensorflow:Writing example 10000 of 256442\n",
      "INFO:tensorflow:Writing example 20000 of 256442\n",
      "INFO:tensorflow:Writing example 30000 of 256442\n",
      "INFO:tensorflow:Writing example 40000 of 256442\n",
      "INFO:tensorflow:Writing example 50000 of 256442\n",
      "INFO:tensorflow:Writing example 60000 of 256442\n",
      "INFO:tensorflow:Writing example 70000 of 256442\n",
      "INFO:tensorflow:Writing example 80000 of 256442\n",
      "INFO:tensorflow:Writing example 90000 of 256442\n",
      "INFO:tensorflow:Writing example 100000 of 256442\n",
      "INFO:tensorflow:Writing example 110000 of 256442\n",
      "INFO:tensorflow:Writing example 120000 of 256442\n",
      "INFO:tensorflow:Writing example 130000 of 256442\n",
      "INFO:tensorflow:Writing example 140000 of 256442\n",
      "INFO:tensorflow:Writing example 150000 of 256442\n",
      "INFO:tensorflow:Writing example 160000 of 256442\n",
      "INFO:tensorflow:Writing example 170000 of 256442\n",
      "INFO:tensorflow:Writing example 180000 of 256442\n",
      "INFO:tensorflow:Writing example 190000 of 256442\n",
      "INFO:tensorflow:Writing example 200000 of 256442\n",
      "INFO:tensorflow:Writing example 210000 of 256442\n",
      "INFO:tensorflow:Writing example 220000 of 256442\n",
      "INFO:tensorflow:Writing example 230000 of 256442\n",
      "INFO:tensorflow:Writing example 240000 of 256442\n",
      "INFO:tensorflow:Writing example 250000 of 256442\n",
      "INFO:tensorflow:Writing example 0 of 64110\n",
      "INFO:tensorflow:Writing example 10000 of 64110\n",
      "INFO:tensorflow:Writing example 20000 of 64110\n",
      "INFO:tensorflow:Writing example 30000 of 64110\n",
      "INFO:tensorflow:Writing example 40000 of 64110\n",
      "INFO:tensorflow:Writing example 50000 of 64110\n",
      "INFO:tensorflow:Writing example 60000 of 64110\n",
      "***** Started training at 2018-12-10 00:09:10.975513 *****\n",
      "  Num examples = 256442\n",
      "  Batch size = 128\n",
      "INFO:tensorflow:  Num steps = 10017\n",
      "INFO:tensorflow:Not using Distribute Coordinator.\n",
      "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n",
      "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps 1000 or save_checkpoints_secs None.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Running train on CPU\n",
      "INFO:tensorflow:*** Features ***\n",
      "INFO:tensorflow:  name = input_ids, shape = (?, 43)\n",
      "INFO:tensorflow:  name = input_mask, shape = (?, 43)\n",
      "INFO:tensorflow:  name = label_ids, shape = (?,)\n",
      "INFO:tensorflow:  name = segment_ids, shape = (?, 43)\n",
      "INFO:tensorflow:**** Trainable Variables ****\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into /home/dmlab/sundong/competition/wsdm2019/fakenews/notebook/results_optimized_chinese_L-12_H-768_A-12/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 1.14737\n",
      "INFO:tensorflow:examples/sec: 146.864\n",
      "INFO:tensorflow:global_step/sec: 1.20205\n",
      "INFO:tensorflow:examples/sec: 153.862\n",
      "INFO:tensorflow:global_step/sec: 1.21928\n",
      "INFO:tensorflow:examples/sec: 156.068\n",
      "INFO:tensorflow:global_step/sec: 1.21382\n",
      "INFO:tensorflow:examples/sec: 155.369\n",
      "INFO:tensorflow:global_step/sec: 1.21443\n",
      "INFO:tensorflow:examples/sec: 155.447\n",
      "INFO:tensorflow:global_step/sec: 1.19659\n",
      "INFO:tensorflow:examples/sec: 153.163\n",
      "INFO:tensorflow:global_step/sec: 1.19292\n",
      "INFO:tensorflow:examples/sec: 152.693\n",
      "INFO:tensorflow:global_step/sec: 1.21385\n",
      "INFO:tensorflow:examples/sec: 155.373\n",
      "INFO:tensorflow:global_step/sec: 1.21196\n",
      "INFO:tensorflow:examples/sec: 155.131\n",
      "INFO:tensorflow:Saving checkpoints for 1000 into /home/dmlab/sundong/competition/wsdm2019/fakenews/notebook/results_optimized_chinese_L-12_H-768_A-12/model.ckpt.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Running eval on CPU\n",
      "INFO:tensorflow:*** Features ***\n",
      "INFO:tensorflow:  name = input_ids, shape = (?, 43)\n",
      "INFO:tensorflow:  name = input_mask, shape = (?, 43)\n",
      "INFO:tensorflow:  name = label_ids, shape = (?,)\n",
      "INFO:tensorflow:  name = segment_ids, shape = (?, 43)\n",
      "INFO:tensorflow:**** Trainable Variables ****\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2018-12-10-08:25:08\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /home/dmlab/sundong/competition/wsdm2019/fakenews/notebook/results_optimized_chinese_L-12_H-768_A-12/model.ckpt-1000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [10/100]\n",
      "INFO:tensorflow:Evaluation [20/100]\n",
      "INFO:tensorflow:Evaluation [30/100]\n",
      "INFO:tensorflow:Evaluation [40/100]\n",
      "INFO:tensorflow:Evaluation [50/100]\n",
      "INFO:tensorflow:Evaluation [60/100]\n",
      "INFO:tensorflow:Evaluation [70/100]\n",
      "INFO:tensorflow:Evaluation [80/100]\n",
      "INFO:tensorflow:Evaluation [90/100]\n",
      "INFO:tensorflow:Evaluation [100/100]\n",
      "INFO:tensorflow:Finished evaluation at 2018-12-10-08:25:38\n",
      "INFO:tensorflow:Saving dict for global step 1000: eval_accuracy = 0.866094, eval_loss = 0.0219494, global_step = 1000, loss = 0.0219494\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 1000: /home/dmlab/sundong/competition/wsdm2019/fakenews/notebook/results_optimized_chinese_L-12_H-768_A-12/model.ckpt-1000\n",
      "INFO:tensorflow:evaluation_loop marked as finished\n",
      "INFO:tensorflow:global_step/sec: 0.770445\n",
      "INFO:tensorflow:examples/sec: 98.617\n",
      "INFO:tensorflow:global_step/sec: 1.20363\n",
      "INFO:tensorflow:examples/sec: 154.065\n",
      "INFO:tensorflow:global_step/sec: 1.20788\n",
      "INFO:tensorflow:examples/sec: 154.609\n",
      "INFO:tensorflow:global_step/sec: 1.21022\n",
      "INFO:tensorflow:examples/sec: 154.908\n",
      "INFO:tensorflow:global_step/sec: 1.20758\n",
      "INFO:tensorflow:examples/sec: 154.57\n",
      "INFO:tensorflow:global_step/sec: 1.17896\n",
      "INFO:tensorflow:examples/sec: 150.907\n",
      "INFO:tensorflow:global_step/sec: 1.1972\n",
      "INFO:tensorflow:examples/sec: 153.241\n",
      "INFO:tensorflow:global_step/sec: 1.21478\n",
      "INFO:tensorflow:examples/sec: 155.492\n",
      "INFO:tensorflow:global_step/sec: 1.21275\n",
      "INFO:tensorflow:examples/sec: 155.232\n",
      "INFO:tensorflow:global_step/sec: 1.2119\n",
      "INFO:tensorflow:examples/sec: 155.123\n",
      "INFO:tensorflow:Saving checkpoints for 2000 into /home/dmlab/sundong/competition/wsdm2019/fakenews/notebook/results_optimized_chinese_L-12_H-768_A-12/model.ckpt.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Running eval on CPU\n",
      "INFO:tensorflow:*** Features ***\n",
      "INFO:tensorflow:  name = input_ids, shape = (?, 43)\n",
      "INFO:tensorflow:  name = input_mask, shape = (?, 43)\n",
      "INFO:tensorflow:  name = label_ids, shape = (?,)\n",
      "INFO:tensorflow:  name = segment_ids, shape = (?, 43)\n",
      "INFO:tensorflow:**** Trainable Variables ****\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2018-12-10-08:39:48\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /home/dmlab/sundong/competition/wsdm2019/fakenews/notebook/results_optimized_chinese_L-12_H-768_A-12/model.ckpt-2000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [10/100]\n",
      "INFO:tensorflow:Evaluation [20/100]\n",
      "INFO:tensorflow:Evaluation [30/100]\n",
      "INFO:tensorflow:Evaluation [40/100]\n",
      "INFO:tensorflow:Evaluation [50/100]\n",
      "INFO:tensorflow:Evaluation [60/100]\n",
      "INFO:tensorflow:Evaluation [70/100]\n",
      "INFO:tensorflow:Evaluation [80/100]\n",
      "INFO:tensorflow:Evaluation [90/100]\n",
      "INFO:tensorflow:Evaluation [100/100]\n",
      "INFO:tensorflow:Finished evaluation at 2018-12-10-08:40:17\n",
      "INFO:tensorflow:Saving dict for global step 2000: eval_accuracy = 0.887578, eval_loss = 0.0193438, global_step = 2000, loss = 0.0193438\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 2000: /home/dmlab/sundong/competition/wsdm2019/fakenews/notebook/results_optimized_chinese_L-12_H-768_A-12/model.ckpt-2000\n",
      "INFO:tensorflow:evaluation_loop marked as finished\n",
      "INFO:tensorflow:global_step/sec: 0.758272\n",
      "INFO:tensorflow:examples/sec: 97.0589\n",
      "INFO:tensorflow:global_step/sec: 1.20924\n",
      "INFO:tensorflow:examples/sec: 154.783\n",
      "INFO:tensorflow:global_step/sec: 1.20784\n",
      "INFO:tensorflow:examples/sec: 154.604\n",
      "INFO:tensorflow:global_step/sec: 1.20125\n",
      "INFO:tensorflow:examples/sec: 153.76\n",
      "INFO:tensorflow:global_step/sec: 1.17741\n",
      "INFO:tensorflow:examples/sec: 150.708\n",
      "INFO:tensorflow:global_step/sec: 1.20557\n",
      "INFO:tensorflow:examples/sec: 154.312\n",
      "INFO:tensorflow:global_step/sec: 1.20735\n",
      "INFO:tensorflow:examples/sec: 154.541\n",
      "INFO:tensorflow:global_step/sec: 1.20307\n",
      "INFO:tensorflow:examples/sec: 153.993\n",
      "INFO:tensorflow:global_step/sec: 1.208\n",
      "INFO:tensorflow:examples/sec: 154.624\n",
      "INFO:tensorflow:global_step/sec: 1.18482\n",
      "INFO:tensorflow:examples/sec: 151.657\n",
      "INFO:tensorflow:Saving checkpoints for 3000 into /home/dmlab/sundong/competition/wsdm2019/fakenews/notebook/results_optimized_chinese_L-12_H-768_A-12/model.ckpt.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Running eval on CPU\n",
      "INFO:tensorflow:*** Features ***\n",
      "INFO:tensorflow:  name = input_ids, shape = (?, 43)\n",
      "INFO:tensorflow:  name = input_mask, shape = (?, 43)\n",
      "INFO:tensorflow:  name = label_ids, shape = (?,)\n",
      "INFO:tensorflow:  name = segment_ids, shape = (?, 43)\n",
      "INFO:tensorflow:**** Trainable Variables ****\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2018-12-10-08:54:28\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /home/dmlab/sundong/competition/wsdm2019/fakenews/notebook/results_optimized_chinese_L-12_H-768_A-12/model.ckpt-3000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [10/100]\n",
      "INFO:tensorflow:Evaluation [20/100]\n",
      "INFO:tensorflow:Evaluation [30/100]\n",
      "INFO:tensorflow:Evaluation [40/100]\n",
      "INFO:tensorflow:Evaluation [50/100]\n",
      "INFO:tensorflow:Evaluation [60/100]\n",
      "INFO:tensorflow:Evaluation [70/100]\n",
      "INFO:tensorflow:Evaluation [80/100]\n",
      "INFO:tensorflow:Evaluation [90/100]\n",
      "INFO:tensorflow:Evaluation [100/100]\n",
      "INFO:tensorflow:Finished evaluation at 2018-12-10-08:54:57\n",
      "INFO:tensorflow:Saving dict for global step 3000: eval_accuracy = 0.891328, eval_loss = 0.0185437, global_step = 3000, loss = 0.0185437\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 3000: /home/dmlab/sundong/competition/wsdm2019/fakenews/notebook/results_optimized_chinese_L-12_H-768_A-12/model.ckpt-3000\n",
      "INFO:tensorflow:evaluation_loop marked as finished\n",
      "INFO:tensorflow:global_step/sec: 0.771223\n",
      "INFO:tensorflow:examples/sec: 98.7166\n",
      "INFO:tensorflow:global_step/sec: 1.21109\n",
      "INFO:tensorflow:examples/sec: 155.019\n",
      "INFO:tensorflow:global_step/sec: 1.19777\n",
      "INFO:tensorflow:examples/sec: 153.314\n",
      "INFO:tensorflow:global_step/sec: 1.1814\n",
      "INFO:tensorflow:examples/sec: 151.22\n",
      "INFO:tensorflow:global_step/sec: 1.21028\n",
      "INFO:tensorflow:examples/sec: 154.915\n",
      "INFO:tensorflow:global_step/sec: 1.21059\n",
      "INFO:tensorflow:examples/sec: 154.956\n",
      "INFO:tensorflow:global_step/sec: 1.21109\n",
      "INFO:tensorflow:examples/sec: 155.019\n",
      "INFO:tensorflow:global_step/sec: 1.20393\n",
      "INFO:tensorflow:examples/sec: 154.103\n",
      "INFO:tensorflow:global_step/sec: 1.18018\n",
      "INFO:tensorflow:examples/sec: 151.063\n",
      "INFO:tensorflow:global_step/sec: 1.21088\n",
      "INFO:tensorflow:examples/sec: 154.992\n",
      "INFO:tensorflow:Saving checkpoints for 4000 into /home/dmlab/sundong/competition/wsdm2019/fakenews/notebook/results_optimized_chinese_L-12_H-768_A-12/model.ckpt.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Running eval on CPU\n",
      "INFO:tensorflow:*** Features ***\n",
      "INFO:tensorflow:  name = input_ids, shape = (?, 43)\n",
      "INFO:tensorflow:  name = input_mask, shape = (?, 43)\n",
      "INFO:tensorflow:  name = label_ids, shape = (?,)\n",
      "INFO:tensorflow:  name = segment_ids, shape = (?, 43)\n",
      "INFO:tensorflow:**** Trainable Variables ****\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2018-12-10-09:09:06\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /home/dmlab/sundong/competition/wsdm2019/fakenews/notebook/results_optimized_chinese_L-12_H-768_A-12/model.ckpt-4000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [10/100]\n",
      "INFO:tensorflow:Evaluation [20/100]\n",
      "INFO:tensorflow:Evaluation [30/100]\n",
      "INFO:tensorflow:Evaluation [40/100]\n",
      "INFO:tensorflow:Evaluation [50/100]\n",
      "INFO:tensorflow:Evaluation [60/100]\n",
      "INFO:tensorflow:Evaluation [70/100]\n",
      "INFO:tensorflow:Evaluation [80/100]\n",
      "INFO:tensorflow:Evaluation [90/100]\n",
      "INFO:tensorflow:Evaluation [100/100]\n",
      "INFO:tensorflow:Finished evaluation at 2018-12-10-09:09:34\n",
      "INFO:tensorflow:Saving dict for global step 4000: eval_accuracy = 0.892969, eval_loss = 0.0182171, global_step = 4000, loss = 0.0182171\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 4000: /home/dmlab/sundong/competition/wsdm2019/fakenews/notebook/results_optimized_chinese_L-12_H-768_A-12/model.ckpt-4000\n",
      "INFO:tensorflow:evaluation_loop marked as finished\n",
      "INFO:tensorflow:global_step/sec: 0.776242\n",
      "INFO:tensorflow:examples/sec: 99.359\n",
      "INFO:tensorflow:global_step/sec: 1.19384\n",
      "INFO:tensorflow:examples/sec: 152.811\n",
      "INFO:tensorflow:global_step/sec: 1.19046\n",
      "INFO:tensorflow:examples/sec: 152.379\n",
      "INFO:tensorflow:global_step/sec: 1.2091\n",
      "INFO:tensorflow:examples/sec: 154.765\n",
      "INFO:tensorflow:global_step/sec: 1.20885\n",
      "INFO:tensorflow:examples/sec: 154.733\n",
      "INFO:tensorflow:global_step/sec: 1.21069\n",
      "INFO:tensorflow:examples/sec: 154.968\n",
      "INFO:tensorflow:global_step/sec: 1.1979\n",
      "INFO:tensorflow:examples/sec: 153.332\n",
      "INFO:tensorflow:global_step/sec: 1.6788\n",
      "INFO:tensorflow:examples/sec: 214.886\n",
      "INFO:tensorflow:global_step/sec: 1.22928\n",
      "INFO:tensorflow:examples/sec: 157.347\n",
      "INFO:tensorflow:global_step/sec: 1.22509\n",
      "INFO:tensorflow:examples/sec: 156.812\n",
      "INFO:tensorflow:Saving checkpoints for 5000 into /home/dmlab/sundong/competition/wsdm2019/fakenews/notebook/results_optimized_chinese_L-12_H-768_A-12/model.ckpt.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Running eval on CPU\n",
      "INFO:tensorflow:*** Features ***\n",
      "INFO:tensorflow:  name = input_ids, shape = (?, 43)\n",
      "INFO:tensorflow:  name = input_mask, shape = (?, 43)\n",
      "INFO:tensorflow:  name = label_ids, shape = (?,)\n",
      "INFO:tensorflow:  name = segment_ids, shape = (?, 43)\n",
      "INFO:tensorflow:**** Trainable Variables ****\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2018-12-10-09:23:16\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /home/dmlab/sundong/competition/wsdm2019/fakenews/notebook/results_optimized_chinese_L-12_H-768_A-12/model.ckpt-5000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [10/100]\n",
      "INFO:tensorflow:Evaluation [20/100]\n",
      "INFO:tensorflow:Evaluation [30/100]\n",
      "INFO:tensorflow:Evaluation [40/100]\n",
      "INFO:tensorflow:Evaluation [50/100]\n",
      "INFO:tensorflow:Evaluation [60/100]\n",
      "INFO:tensorflow:Evaluation [70/100]\n",
      "INFO:tensorflow:Evaluation [80/100]\n",
      "INFO:tensorflow:Evaluation [90/100]\n",
      "INFO:tensorflow:Evaluation [100/100]\n",
      "INFO:tensorflow:Finished evaluation at 2018-12-10-09:23:44\n",
      "INFO:tensorflow:Saving dict for global step 5000: eval_accuracy = 0.897734, eval_loss = 0.0184685, global_step = 5000, loss = 0.0184685\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 5000: /home/dmlab/sundong/competition/wsdm2019/fakenews/notebook/results_optimized_chinese_L-12_H-768_A-12/model.ckpt-5000\n",
      "INFO:tensorflow:evaluation_loop marked as finished\n",
      "INFO:tensorflow:global_step/sec: 0.783951\n",
      "INFO:tensorflow:examples/sec: 100.346\n",
      "INFO:tensorflow:global_step/sec: 1.21512\n",
      "INFO:tensorflow:examples/sec: 155.536\n",
      "INFO:tensorflow:global_step/sec: 1.2189\n",
      "INFO:tensorflow:examples/sec: 156.019\n",
      "INFO:tensorflow:global_step/sec: 1.21967\n",
      "INFO:tensorflow:examples/sec: 156.118\n",
      "INFO:tensorflow:global_step/sec: 1.21308\n",
      "INFO:tensorflow:examples/sec: 155.274\n",
      "INFO:tensorflow:global_step/sec: 1.1879\n",
      "INFO:tensorflow:examples/sec: 152.051\n",
      "INFO:tensorflow:global_step/sec: 1.21451\n",
      "INFO:tensorflow:examples/sec: 155.457\n",
      "INFO:tensorflow:global_step/sec: 1.21477\n",
      "INFO:tensorflow:examples/sec: 155.49\n",
      "INFO:tensorflow:global_step/sec: 1.21471\n",
      "INFO:tensorflow:examples/sec: 155.483\n",
      "INFO:tensorflow:global_step/sec: 1.20926\n",
      "INFO:tensorflow:examples/sec: 154.786\n",
      "INFO:tensorflow:Saving checkpoints for 6000 into /home/dmlab/sundong/competition/wsdm2019/fakenews/notebook/results_optimized_chinese_L-12_H-768_A-12/model.ckpt.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Running eval on CPU\n",
      "INFO:tensorflow:*** Features ***\n",
      "INFO:tensorflow:  name = input_ids, shape = (?, 43)\n",
      "INFO:tensorflow:  name = input_mask, shape = (?, 43)\n",
      "INFO:tensorflow:  name = label_ids, shape = (?,)\n",
      "INFO:tensorflow:  name = segment_ids, shape = (?, 43)\n",
      "INFO:tensorflow:**** Trainable Variables ****\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2018-12-10-09:37:48\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /home/dmlab/sundong/competition/wsdm2019/fakenews/notebook/results_optimized_chinese_L-12_H-768_A-12/model.ckpt-6000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [10/100]\n",
      "INFO:tensorflow:Evaluation [20/100]\n",
      "INFO:tensorflow:Evaluation [30/100]\n",
      "INFO:tensorflow:Evaluation [40/100]\n",
      "INFO:tensorflow:Evaluation [50/100]\n",
      "INFO:tensorflow:Evaluation [60/100]\n",
      "INFO:tensorflow:Evaluation [70/100]\n",
      "INFO:tensorflow:Evaluation [80/100]\n",
      "INFO:tensorflow:Evaluation [90/100]\n",
      "INFO:tensorflow:Evaluation [100/100]\n",
      "INFO:tensorflow:Finished evaluation at 2018-12-10-09:38:17\n",
      "INFO:tensorflow:Saving dict for global step 6000: eval_accuracy = 0.901016, eval_loss = 0.0184258, global_step = 6000, loss = 0.0184258\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 6000: /home/dmlab/sundong/competition/wsdm2019/fakenews/notebook/results_optimized_chinese_L-12_H-768_A-12/model.ckpt-6000\n",
      "INFO:tensorflow:evaluation_loop marked as finished\n",
      "INFO:tensorflow:global_step/sec: 0.76811\n",
      "INFO:tensorflow:examples/sec: 98.3181\n",
      "INFO:tensorflow:global_step/sec: 1.21559\n",
      "INFO:tensorflow:examples/sec: 155.596\n",
      "INFO:tensorflow:global_step/sec: 1.21588\n",
      "INFO:tensorflow:examples/sec: 155.633\n",
      "INFO:tensorflow:global_step/sec: 1.19253\n",
      "INFO:tensorflow:examples/sec: 152.644\n",
      "INFO:tensorflow:global_step/sec: 1.20843\n",
      "INFO:tensorflow:examples/sec: 154.679\n",
      "INFO:tensorflow:global_step/sec: 1.21696\n",
      "INFO:tensorflow:examples/sec: 155.77\n",
      "INFO:tensorflow:global_step/sec: 1.21648\n",
      "INFO:tensorflow:examples/sec: 155.71\n",
      "INFO:tensorflow:global_step/sec: 1.21704\n",
      "INFO:tensorflow:examples/sec: 155.782\n",
      "INFO:tensorflow:global_step/sec: 1.18881\n",
      "INFO:tensorflow:examples/sec: 152.168\n",
      "INFO:tensorflow:global_step/sec: 1.20895\n",
      "INFO:tensorflow:examples/sec: 154.745\n",
      "INFO:tensorflow:Saving checkpoints for 7000 into /home/dmlab/sundong/competition/wsdm2019/fakenews/notebook/results_optimized_chinese_L-12_H-768_A-12/model.ckpt.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Running eval on CPU\n",
      "INFO:tensorflow:*** Features ***\n",
      "INFO:tensorflow:  name = input_ids, shape = (?, 43)\n",
      "INFO:tensorflow:  name = input_mask, shape = (?, 43)\n",
      "INFO:tensorflow:  name = label_ids, shape = (?,)\n",
      "INFO:tensorflow:  name = segment_ids, shape = (?, 43)\n",
      "INFO:tensorflow:**** Trainable Variables ****\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2018-12-10-09:52:22\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /home/dmlab/sundong/competition/wsdm2019/fakenews/notebook/results_optimized_chinese_L-12_H-768_A-12/model.ckpt-7000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [10/100]\n",
      "INFO:tensorflow:Evaluation [20/100]\n",
      "INFO:tensorflow:Evaluation [30/100]\n",
      "INFO:tensorflow:Evaluation [40/100]\n",
      "INFO:tensorflow:Evaluation [50/100]\n",
      "INFO:tensorflow:Evaluation [60/100]\n",
      "INFO:tensorflow:Evaluation [70/100]\n",
      "INFO:tensorflow:Evaluation [80/100]\n",
      "INFO:tensorflow:Evaluation [90/100]\n",
      "INFO:tensorflow:Evaluation [100/100]\n",
      "INFO:tensorflow:Finished evaluation at 2018-12-10-09:52:50\n",
      "INFO:tensorflow:Saving dict for global step 7000: eval_accuracy = 0.899297, eval_loss = 0.0204231, global_step = 7000, loss = 0.0204231\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 7000: /home/dmlab/sundong/competition/wsdm2019/fakenews/notebook/results_optimized_chinese_L-12_H-768_A-12/model.ckpt-7000\n",
      "INFO:tensorflow:evaluation_loop marked as finished\n",
      "INFO:tensorflow:global_step/sec: 0.778574\n",
      "INFO:tensorflow:examples/sec: 99.6575\n",
      "INFO:tensorflow:global_step/sec: 1.20147\n",
      "INFO:tensorflow:examples/sec: 153.788\n",
      "INFO:tensorflow:global_step/sec: 1.1964\n",
      "INFO:tensorflow:examples/sec: 153.14\n",
      "INFO:tensorflow:global_step/sec: 1.2149\n",
      "INFO:tensorflow:examples/sec: 155.508\n",
      "INFO:tensorflow:global_step/sec: 1.21572\n",
      "INFO:tensorflow:examples/sec: 155.613\n",
      "INFO:tensorflow:global_step/sec: 1.21475\n",
      "INFO:tensorflow:examples/sec: 155.488\n",
      "INFO:tensorflow:global_step/sec: 1.20193\n",
      "INFO:tensorflow:examples/sec: 153.847\n",
      "INFO:tensorflow:global_step/sec: 1.20014\n",
      "INFO:tensorflow:examples/sec: 153.618\n",
      "INFO:tensorflow:global_step/sec: 1.21953\n",
      "INFO:tensorflow:examples/sec: 156.1\n",
      "INFO:tensorflow:global_step/sec: 1.21688\n",
      "INFO:tensorflow:examples/sec: 155.76\n",
      "INFO:tensorflow:Saving checkpoints for 8000 into /home/dmlab/sundong/competition/wsdm2019/fakenews/notebook/results_optimized_chinese_L-12_H-768_A-12/model.ckpt.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Running eval on CPU\n",
      "INFO:tensorflow:*** Features ***\n",
      "INFO:tensorflow:  name = input_ids, shape = (?, 43)\n",
      "INFO:tensorflow:  name = input_mask, shape = (?, 43)\n",
      "INFO:tensorflow:  name = label_ids, shape = (?,)\n",
      "INFO:tensorflow:  name = segment_ids, shape = (?, 43)\n",
      "INFO:tensorflow:**** Trainable Variables ****\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2018-12-10-10:06:54\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /home/dmlab/sundong/competition/wsdm2019/fakenews/notebook/results_optimized_chinese_L-12_H-768_A-12/model.ckpt-8000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [10/100]\n",
      "INFO:tensorflow:Evaluation [20/100]\n",
      "INFO:tensorflow:Evaluation [30/100]\n",
      "INFO:tensorflow:Evaluation [40/100]\n",
      "INFO:tensorflow:Evaluation [50/100]\n",
      "INFO:tensorflow:Evaluation [60/100]\n",
      "INFO:tensorflow:Evaluation [70/100]\n",
      "INFO:tensorflow:Evaluation [80/100]\n",
      "INFO:tensorflow:Evaluation [90/100]\n",
      "INFO:tensorflow:Evaluation [100/100]\n",
      "INFO:tensorflow:Finished evaluation at 2018-12-10-10:07:22\n",
      "INFO:tensorflow:Saving dict for global step 8000: eval_accuracy = 0.902422, eval_loss = 0.0200111, global_step = 8000, loss = 0.0200111\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 8000: /home/dmlab/sundong/competition/wsdm2019/fakenews/notebook/results_optimized_chinese_L-12_H-768_A-12/model.ckpt-8000\n",
      "INFO:tensorflow:evaluation_loop marked as finished\n",
      "INFO:tensorflow:global_step/sec: 0.779285\n",
      "INFO:tensorflow:examples/sec: 99.7484\n",
      "INFO:tensorflow:global_step/sec: 1.22475\n",
      "INFO:tensorflow:examples/sec: 156.768\n",
      "INFO:tensorflow:global_step/sec: 1.2153\n",
      "INFO:tensorflow:examples/sec: 155.559\n",
      "INFO:tensorflow:global_step/sec: 1.21557\n",
      "INFO:tensorflow:examples/sec: 155.593\n",
      "INFO:tensorflow:global_step/sec: 1.19946\n",
      "INFO:tensorflow:examples/sec: 153.531\n",
      "INFO:tensorflow:global_step/sec: 1.19425\n",
      "INFO:tensorflow:examples/sec: 152.864\n",
      "INFO:tensorflow:global_step/sec: 1.21778\n",
      "INFO:tensorflow:examples/sec: 155.876\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 1.21784\n",
      "INFO:tensorflow:examples/sec: 155.884\n",
      "INFO:tensorflow:global_step/sec: 1.2198\n",
      "INFO:tensorflow:examples/sec: 156.135\n",
      "INFO:tensorflow:global_step/sec: 1.20242\n",
      "INFO:tensorflow:examples/sec: 153.909\n",
      "INFO:tensorflow:Saving checkpoints for 9000 into /home/dmlab/sundong/competition/wsdm2019/fakenews/notebook/results_optimized_chinese_L-12_H-768_A-12/model.ckpt.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Running eval on CPU\n",
      "INFO:tensorflow:*** Features ***\n",
      "INFO:tensorflow:  name = input_ids, shape = (?, 43)\n",
      "INFO:tensorflow:  name = input_mask, shape = (?, 43)\n",
      "INFO:tensorflow:  name = label_ids, shape = (?,)\n",
      "INFO:tensorflow:  name = segment_ids, shape = (?, 43)\n",
      "INFO:tensorflow:**** Trainable Variables ****\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2018-12-10-10:21:26\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /home/dmlab/sundong/competition/wsdm2019/fakenews/notebook/results_optimized_chinese_L-12_H-768_A-12/model.ckpt-9000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [10/100]\n",
      "INFO:tensorflow:Evaluation [20/100]\n",
      "INFO:tensorflow:Evaluation [30/100]\n",
      "INFO:tensorflow:Evaluation [40/100]\n",
      "INFO:tensorflow:Evaluation [50/100]\n",
      "INFO:tensorflow:Evaluation [60/100]\n",
      "INFO:tensorflow:Evaluation [70/100]\n",
      "INFO:tensorflow:Evaluation [80/100]\n",
      "INFO:tensorflow:Evaluation [90/100]\n",
      "INFO:tensorflow:Evaluation [100/100]\n",
      "INFO:tensorflow:Finished evaluation at 2018-12-10-10:21:55\n",
      "INFO:tensorflow:Saving dict for global step 9000: eval_accuracy = 0.899141, eval_loss = 0.0217229, global_step = 9000, loss = 0.0217229\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 9000: /home/dmlab/sundong/competition/wsdm2019/fakenews/notebook/results_optimized_chinese_L-12_H-768_A-12/model.ckpt-9000\n",
      "INFO:tensorflow:evaluation_loop marked as finished\n",
      "INFO:tensorflow:global_step/sec: 0.769058\n",
      "INFO:tensorflow:examples/sec: 98.4394\n",
      "INFO:tensorflow:global_step/sec: 1.22108\n",
      "INFO:tensorflow:examples/sec: 156.298\n",
      "INFO:tensorflow:global_step/sec: 1.21103\n",
      "INFO:tensorflow:examples/sec: 155.011\n",
      "INFO:tensorflow:global_step/sec: 1.18814\n",
      "INFO:tensorflow:examples/sec: 152.081\n",
      "INFO:tensorflow:global_step/sec: 1.67023\n",
      "INFO:tensorflow:examples/sec: 213.789\n",
      "INFO:tensorflow:global_step/sec: 1.25987\n",
      "INFO:tensorflow:examples/sec: 161.263\n",
      "INFO:tensorflow:global_step/sec: 1.25176\n",
      "INFO:tensorflow:examples/sec: 160.226\n",
      "INFO:tensorflow:global_step/sec: 1.21734\n",
      "INFO:tensorflow:examples/sec: 155.82\n",
      "INFO:tensorflow:global_step/sec: 1.19763\n",
      "INFO:tensorflow:examples/sec: 153.296\n",
      "INFO:tensorflow:global_step/sec: 1.22584\n",
      "INFO:tensorflow:examples/sec: 156.907\n",
      "INFO:tensorflow:Saving checkpoints for 10000 into /home/dmlab/sundong/competition/wsdm2019/fakenews/notebook/results_optimized_chinese_L-12_H-768_A-12/model.ckpt.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Running eval on CPU\n",
      "INFO:tensorflow:*** Features ***\n",
      "INFO:tensorflow:  name = input_ids, shape = (?, 43)\n",
      "INFO:tensorflow:  name = input_mask, shape = (?, 43)\n",
      "INFO:tensorflow:  name = label_ids, shape = (?,)\n",
      "INFO:tensorflow:  name = segment_ids, shape = (?, 43)\n",
      "INFO:tensorflow:**** Trainable Variables ****\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2018-12-10-10:35:30\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /home/dmlab/sundong/competition/wsdm2019/fakenews/notebook/results_optimized_chinese_L-12_H-768_A-12/model.ckpt-10000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [10/100]\n",
      "INFO:tensorflow:Evaluation [20/100]\n",
      "INFO:tensorflow:Evaluation [30/100]\n",
      "INFO:tensorflow:Evaluation [40/100]\n",
      "INFO:tensorflow:Evaluation [50/100]\n",
      "INFO:tensorflow:Evaluation [60/100]\n",
      "INFO:tensorflow:Evaluation [70/100]\n",
      "INFO:tensorflow:Evaluation [80/100]\n",
      "INFO:tensorflow:Evaluation [90/100]\n",
      "INFO:tensorflow:Evaluation [100/100]\n",
      "INFO:tensorflow:Finished evaluation at 2018-12-10-10:35:56\n",
      "INFO:tensorflow:Saving dict for global step 10000: eval_accuracy = 0.901328, eval_loss = 0.0211841, global_step = 10000, loss = 0.0211841\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 10000: /home/dmlab/sundong/competition/wsdm2019/fakenews/notebook/results_optimized_chinese_L-12_H-768_A-12/model.ckpt-10000\n",
      "INFO:tensorflow:evaluation_loop marked as finished\n",
      "INFO:tensorflow:global_step/sec: 0.793313\n",
      "INFO:tensorflow:examples/sec: 101.544\n",
      "INFO:tensorflow:Saving checkpoints for 10017 into /home/dmlab/sundong/competition/wsdm2019/fakenews/notebook/results_optimized_chinese_L-12_H-768_A-12/model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (600 secs).\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Running eval on CPU\n",
      "INFO:tensorflow:*** Features ***\n",
      "INFO:tensorflow:  name = input_ids, shape = (?, 43)\n",
      "INFO:tensorflow:  name = input_mask, shape = (?, 43)\n",
      "INFO:tensorflow:  name = label_ids, shape = (?,)\n",
      "INFO:tensorflow:  name = segment_ids, shape = (?, 43)\n",
      "INFO:tensorflow:**** Trainable Variables ****\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2018-12-10-10:36:29\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /home/dmlab/sundong/competition/wsdm2019/fakenews/notebook/results_optimized_chinese_L-12_H-768_A-12/model.ckpt-10017\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [10/100]\n",
      "INFO:tensorflow:Evaluation [20/100]\n",
      "INFO:tensorflow:Evaluation [30/100]\n",
      "INFO:tensorflow:Evaluation [40/100]\n",
      "INFO:tensorflow:Evaluation [50/100]\n",
      "INFO:tensorflow:Evaluation [60/100]\n",
      "INFO:tensorflow:Evaluation [70/100]\n",
      "INFO:tensorflow:Evaluation [80/100]\n",
      "INFO:tensorflow:Evaluation [90/100]\n",
      "INFO:tensorflow:Evaluation [100/100]\n",
      "INFO:tensorflow:Finished evaluation at 2018-12-10-10:36:58\n",
      "INFO:tensorflow:Saving dict for global step 10017: eval_accuracy = 0.901328, eval_loss = 0.021183, global_step = 10017, loss = 0.021183\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 10017: /home/dmlab/sundong/competition/wsdm2019/fakenews/notebook/results_optimized_chinese_L-12_H-768_A-12/model.ckpt-10017\n",
      "INFO:tensorflow:evaluation_loop marked as finished\n",
      "INFO:tensorflow:Loss for final step: 0.00488486.\n",
      "INFO:tensorflow:training_loop marked as finished\n",
      "INFO:tensorflow:Writing example 0 of 80126\n",
      "INFO:tensorflow:Writing example 10000 of 80126\n",
      "INFO:tensorflow:Writing example 20000 of 80126\n",
      "INFO:tensorflow:Writing example 30000 of 80126\n",
      "INFO:tensorflow:Writing example 40000 of 80126\n",
      "INFO:tensorflow:Writing example 50000 of 80126\n",
      "INFO:tensorflow:Writing example 60000 of 80126\n",
      "INFO:tensorflow:Writing example 70000 of 80126\n",
      "INFO:tensorflow:Writing example 80000 of 80126\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Running infer on CPU\n",
      "INFO:tensorflow:*** Features ***\n",
      "INFO:tensorflow:  name = input_ids, shape = (?, 43)\n",
      "INFO:tensorflow:  name = input_mask, shape = (?, 43)\n",
      "INFO:tensorflow:  name = label_ids, shape = (?,)\n",
      "INFO:tensorflow:  name = segment_ids, shape = (?, 43)\n",
      "INFO:tensorflow:**** Trainable Variables ****\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /home/dmlab/sundong/competition/wsdm2019/fakenews/notebook/results_optimized_chinese_L-12_H-768_A-12/model.ckpt-10017\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:prediction_loop marked as finished\n",
      "INFO:tensorflow:prediction_loop marked as finished\n"
     ]
    }
   ],
   "source": [
    "# Available pretrained model checkpoints:\n",
    "#   uncased_L-12_H-768_A-12: uncased BERT base model\n",
    "#   uncased_L-24_H-1024_A-16: uncased BERT large model\n",
    "#   cased_L-12_H-768_A-12: cased BERT large model\n",
    "\n",
    "exp_marker = 'crude-ensemble-geomean'\n",
    "TASK_DATA_DIR = '../data/FakeNews_BERT/FakeNews_BERT/'\n",
    "\n",
    "\n",
    "# BERT_MODEL_LIST = ['chinese_L-12_H-768_A-12', 'multi_cased_L-12_H-768_A-12', 'uncased_L-24_H-1024_A-16']\n",
    "BERT_MODEL_LIST = ['chinese_L-12_H-768_A-12']\n",
    "\n",
    "for BERT_MODEL in BERT_MODEL_LIST:\n",
    "    BERT_PRETRAINED_DIR = '../data/' + BERT_MODEL\n",
    "    OUTPUT_DIR = '/home/dmlab/sundong/competition/wsdm2019/fakenews/notebook/results_optimized_'+BERT_MODEL\n",
    "\n",
    "    print('***** BERT pretrained directory: {} *****'.format(BERT_PRETRAINED_DIR))\n",
    "    print('***** Model output directory: {} *****'.format(OUTPUT_DIR))\n",
    "    \n",
    "    if BERT_MODEL == 'uncased_L-24_H-1024_A-16':\n",
    "        TRAIN_BATCH_SIZE = 12\n",
    "        EVAL_BATCH_SIZE = 12\n",
    "        TEST_BATCH_SIZE = 12\n",
    "        LEARNING_RATE = 2e-5\n",
    "        NUM_TRAIN_EPOCHS = 3.0\n",
    "        WARMUP_PROPORTION = 0.1\n",
    "        MAX_SEQ_LENGTH = 43  # According to our dataset, length of 43 can cover 99.5% of the titles.\n",
    "        TASK = 'FakeEN' \n",
    "    else:\n",
    "        # Model Hyper Parameters\n",
    "        TRAIN_BATCH_SIZE = 128 # 32\n",
    "        EVAL_BATCH_SIZE = 128  # 8    \n",
    "        TEST_BATCH_SIZE = 128  # 8    \n",
    "        LEARNING_RATE = 2e-5\n",
    "        NUM_TRAIN_EPOCHS = 5.0\n",
    "        WARMUP_PROPORTION = 0.1\n",
    "        MAX_SEQ_LENGTH = 43  # According to our dataset, length of 43 can cover 99.5% of the titles.\n",
    "        TASK = 'Fake'\n",
    "        \n",
    "    # Model configs\n",
    "    SAVE_CHECKPOINTS_STEPS = 1000\n",
    "    ITERATIONS_PER_LOOP = 1000\n",
    "    NUM_TPU_CORES = 8\n",
    "    VOCAB_FILE = os.path.join(BERT_PRETRAINED_DIR, 'vocab.txt')\n",
    "    CONFIG_FILE = os.path.join(BERT_PRETRAINED_DIR, 'bert_config.json')\n",
    "    INIT_CHECKPOINT = os.path.join(BERT_PRETRAINED_DIR, 'bert_model.ckpt')\n",
    "    DO_LOWER_CASE = BERT_MODEL.startswith('uncased')\n",
    "\n",
    "    processors = {\n",
    "      \"cola\": run_classifier.ColaProcessor,\n",
    "      \"mnli\": run_classifier.MnliProcessor,\n",
    "      \"mrpc\": run_classifier.MrpcProcessor,\n",
    "      \"fake\": run_classifier.FakeProcessor,\n",
    "      \"fakeen\": run_classifier.FakeENProcessor,  \n",
    "    }\n",
    "    processor = processors[TASK.lower()]()\n",
    "    label_list = processor.get_labels()\n",
    "    \n",
    "    tokenizer = tokenization.FullTokenizer(vocab_file=VOCAB_FILE, do_lower_case=DO_LOWER_CASE)\n",
    "    tpu_cluster_resolver = None\n",
    "    \n",
    "#     run_config = tf.estimator.RunConfig(\n",
    "#         model_dir=OUTPUT_DIR,\n",
    "#         save_checkpoints_steps=SAVE_CHECKPOINTS_STEPS,\n",
    "#     )\n",
    "\n",
    "    run_config = tf.contrib.tpu.RunConfig(\n",
    "        cluster=tpu_cluster_resolver,\n",
    "        model_dir=OUTPUT_DIR,\n",
    "        save_checkpoints_steps=SAVE_CHECKPOINTS_STEPS,\n",
    "        tpu_config=tf.contrib.tpu.TPUConfig(\n",
    "            iterations_per_loop=ITERATIONS_PER_LOOP,\n",
    "            num_shards=NUM_TPU_CORES,\n",
    "            per_host_input_for_training=tf.contrib.tpu.InputPipelineConfig.PER_HOST_V2))\n",
    "    \n",
    "\n",
    "    train_examples = processor.get_train_examples(TASK_DATA_DIR)\n",
    "    eval_examples = processor.get_dev_examples(TASK_DATA_DIR)\n",
    "\n",
    "    num_train_steps = int(\n",
    "        len(train_examples) / TRAIN_BATCH_SIZE * NUM_TRAIN_EPOCHS)\n",
    "    num_warmup_steps = int(num_train_steps * WARMUP_PROPORTION)\n",
    "\n",
    "    model_fn = run_classifier.model_fn_builder(\n",
    "        bert_config=modeling.BertConfig.from_json_file(CONFIG_FILE),\n",
    "        num_labels=len(label_list),\n",
    "        init_checkpoint=INIT_CHECKPOINT,\n",
    "        learning_rate=LEARNING_RATE,\n",
    "        num_train_steps=num_train_steps,\n",
    "        num_warmup_steps=num_warmup_steps,\n",
    "        use_tpu = False,\n",
    "        use_one_hot_embeddings=True)\n",
    "    \n",
    "    estimator = tf.contrib.tpu.TPUEstimator(\n",
    "        use_tpu=False,\n",
    "        model_fn=model_fn,\n",
    "        config=run_config,\n",
    "        train_batch_size=TRAIN_BATCH_SIZE,\n",
    "        eval_batch_size=EVAL_BATCH_SIZE)\n",
    "    \n",
    "    \n",
    "    # Train the model.\n",
    "    print('Feature generating with train data')\n",
    "    \n",
    "    train_features = run_classifier.convert_examples_to_features(\n",
    "        train_examples, label_list, MAX_SEQ_LENGTH, tokenizer)\n",
    "    \n",
    "    eval_features = run_classifier.convert_examples_to_features(\n",
    "        eval_examples, label_list, MAX_SEQ_LENGTH, tokenizer)\n",
    "    \n",
    "    \n",
    "    print('***** Started training at {} *****'.format(datetime.datetime.now()))\n",
    "    print('  Num examples = {}'.format(len(train_examples)))\n",
    "    print('  Batch size = {}'.format(TRAIN_BATCH_SIZE))\n",
    "    tf.logging.info(\"  Num steps = %d\", num_train_steps)\n",
    "    \n",
    "    train_input_fn = run_classifier.input_fn_builder(\n",
    "        features=train_features,\n",
    "        seq_length=MAX_SEQ_LENGTH,\n",
    "        is_training=True,\n",
    "        drop_remainder=False)\n",
    "    \n",
    "    \n",
    "    eval_input_fn = input_fn_builder(\n",
    "        features=eval_features,\n",
    "        seq_length=MAX_SEQ_LENGTH,\n",
    "        is_training=False,\n",
    "        drop_remainder=False)\n",
    "    \n",
    "    \n",
    "    train_spec = tf.estimator.TrainSpec(input_fn=train_input_fn, max_steps=num_train_steps)\n",
    "    eval_spec = tf.estimator.EvalSpec(input_fn=eval_input_fn)\n",
    "    \n",
    "    tf.estimator.train_and_evaluate(estimator, train_spec, eval_spec)\n",
    "    \n",
    "#     estimator.train(input_fn=train_input_fn, max_steps=num_train_steps)\n",
    "#     print('***** Finished training at {} *****'.format(datetime.datetime.now()))\n",
    "\n",
    "    \n",
    "    \n",
    "    # Test the model.\n",
    "    test_examples = processor.get_test_examples(TASK_DATA_DIR)\n",
    "    test_features = run_classifier.convert_examples_to_features(\n",
    "        test_examples, label_list, MAX_SEQ_LENGTH, tokenizer)\n",
    "\n",
    "    # Eval will be slightly WRONG on the TPU because it will truncate\n",
    "    # the last batch.\n",
    "    test_input_fn = input_fn_builder(          # run_classifier.\n",
    "        features=test_features,\n",
    "        seq_length=MAX_SEQ_LENGTH,\n",
    "        is_training=False,\n",
    "        drop_remainder=False)\n",
    "\n",
    "    result = estimator.predict(input_fn=test_input_fn)\n",
    "\n",
    "    raw_result_list = []\n",
    "    result_list = []\n",
    "    for rr in result:\n",
    "        raw_result_list.append(rr)\n",
    "        result_list.append(np.argmax(rr))\n",
    "\n",
    "        \n",
    "    test_path = '../data/test.csv'\n",
    "    submission_path = '../data/sample_submission_BERTopt_'+BERT_MODEL+'.csv'\n",
    "    submission_all_path = '../data/sample_submission_BERTopt_'+BERT_MODEL+'_ALL.csv'\n",
    "    result_raw_path = '../data/sample_submission_sd_BERTopt_'+BERT_MODEL+'_RESULT_SOFTMAX.p'\n",
    "    df_test = pd.read_csv(test_path)\n",
    "    df_test['pred_label'] = result_list\n",
    "    idx_label = {0:'unrelated', 1:'agreed', 2:'disagreed'}\n",
    "    df_test['pred_label'] = df_test['pred_label'].apply(lambda x: idx_label[x])\n",
    "\n",
    "    df_test[['id', 'pred_label']].rename(columns={'id':'Id','pred_label':'Category'}).to_csv(submission_path, index=False)\n",
    "    df_test.to_csv(submission_all_path, index=False)\n",
    "\n",
    "    pickle.dump(raw_result_list, open(result_raw_path, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Geomean\n",
    "\n",
    "submission_ensemble_path = '../data/sample_submission_sd_BERT_weightedavg_4model_cn.csv'\n",
    "smax = {}\n",
    "BERT_MODEL_LIST = ['chinese_L-12_H-768_A-12', 'chinese_L-12_H-768_A-12_EN', 'multi_cased_L-12_H-768_A-12', 'uncased_L-24_H-1024_A-16']\n",
    "# BERT_MODEL_LIST = ['chinese_L-12_H-768_A-12']\n",
    "for BERT_MODEL in BERT_MODEL_LIST: \n",
    "    pkls_path = '../data/sample_submission_sd_BERT_'+BERT_MODEL+'_RESULT_SOFTMAX.p'\n",
    "    with open(pkls_path, 'rb') as file:\n",
    "        smax[BERT_MODEL] = np.asarray(pickle.load(file))\n",
    "        \n",
    "# ens_rslt = np.multiply(smax['chinese_L-12_H-768_A-12', smax['multi_cased_L-12_H-768_A-12'], smax['uncased_L-24_H-1024_A-16']])   \n",
    "ens_rslt = np.average(np.array([smax['chinese_L-12_H-768_A-12'], smax['multi_cased_L-12_H-768_A-12'], smax['uncased_L-24_H-1024_A-16'], smax['chinese_L-12_H-768_A-12_EN']]), \n",
    "                      axis=0, weights=[0.6,0.1,0.1,0.2])\n",
    "\n",
    "\n",
    "df_test = pd.read_csv(test_path)\n",
    "df_test['pred_label'] = np.argmax(ens_rslt, axis=1)\n",
    "idx_label = {0:'unrelated', 1:'agreed', 2:'disagreed'}\n",
    "df_test['pred_label'] = df_test['pred_label'].apply(lambda x: idx_label[x])\n",
    "\n",
    "df_test[['id', 'pred_label']].rename(columns={'id':'Id','pred_label':'Category'}).to_csv(submission_ensemble_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ens_rslt = np.average(np.array([smax['chinese_L-12_H-768_A-12'], smax['multi_cased_L-12_H-768_A-12'], smax['uncased_L-24_H-1024_A-16'], smax['chinese_L-12_H-768_A-12_EN']]), \n",
    "                      axis=0, weights=[0.6,0.1,0.1,0.2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ens_rslt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_test['pred_label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('../data/train.csv')\n",
    "dft_tr = df_train['label'].value_counts()\n",
    "dft_tr/np.sum(dft_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dft = df_test['pred_label'].value_counts()\n",
    "dft/np.sum(dft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
