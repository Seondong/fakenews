{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* https://www.kaggle.com/c/fake-news-pair-classification-challenge/data\n",
    "* https://github.com/fxsjy/jieba\n",
    "\n",
    "BERT\n",
    "* https://colab.research.google.com/github/tensorflow/tpu/blob/master/tools/colab/bert_finetuning_with_cloud_tpus.ipynb#scrollTo=Hcpfl4N2EdOk\n",
    "* https://github.com/google-research/bert/blob/master/multilingual.md\n",
    "\n",
    "Gluon-bert\n",
    "* https://gluon-nlp.mxnet.io/examples/sentence_embedding/bert.html\n",
    "\n",
    "Embedding options\n",
    "* https://github.com/Embedding/Chinese-Word-Vectors (Embedding 1)\n",
    "* https://github.com/facebookresearch/fastText/blob/master/docs/crawl-vectors.md (Embedding 2)\n",
    "\n",
    "Performance\n",
    "* Using Embedding 1: Performance 0.70640\n",
    "* Using Embedding 2: Performance 0.68641\n",
    "* Using BERT: Performance 0.849\n",
    "* Using BERT_WEIGHTED: Performance 0.85526\n",
    "* Using BERT_WEIGHTED+SameTID-Agreed: 0.85479\n",
    "    * Example: df_test[df_test.pred_label != df_test.pred_label2]인 아이들 다 agreed\n",
    "* Using BERT_WEIGHTED_train100: Performance 0.85634\n",
    "* Using BERT_ensemble_3models (cn, multi, uncased24): Performance 0.85619\n",
    "* Using BERT_ensemble_4models_weighted (cn, cnen, multi, uncased24): Performance 0.86283\n",
    "\n",
    "내일 submission: train / validation을 통해 epoch 최고값 잡고, 여러모델 최종값 merge "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Geomean\n",
    "\n",
    "method = 'all_average_9_BERT_cn_model'\n",
    "submission_ensemble_path = '../data/sample_submission_BERT_'+method+'.csv'\n",
    "\n",
    "\n",
    "smax = {}\n",
    "\n",
    "# BERT_MODEL_LIST = ['chinese_L-12_H-768_A-12', 'chinese_L-12_H-768_A-12_EN', 'multi_cased_L-12_H-768_A-12', 'uncased_L-24_H-1024_A-16']\n",
    "BERT_MODEL_LIST = ['chinese_L-12_H-768_A-12']\n",
    "\n",
    "for BERT_MODEL in BERT_MODEL_LIST: \n",
    "    for numrun in range(1,10):\n",
    "        pkls_path = '../data/sample_submission_sd_BERTopt'+str(numrun)+'_'+BERT_MODEL+'_RESULT_SOFTMAX.p'\n",
    "        with open(pkls_path, 'rb') as file:\n",
    "            smax[str(numrun)+'_'+BERT_MODEL] = np.asarray(pickle.load(file))\n",
    "        \n",
    "# ens_rslt = np.multiply(smax['chinese_L-12_H-768_A-12', smax['multi_cased_L-12_H-768_A-12'], smax['uncased_L-24_H-1024_A-16']])   \n",
    "# ens_rslt = np.average(np.array([smax['chinese_L-12_H-768_A-12'], smax['multi_cased_L-12_H-768_A-12'], smax['uncased_L-24_H-1024_A-16'], smax['chinese_L-12_H-768_A-12_EN']]), \n",
    "#                       axis=0, weights=[0.6,0.1,0.1,0.2])\n",
    "\n",
    "\n",
    "ens_rslt = np.average(np.array([smax[key] for key in smax.keys()]), axis=0)\n",
    "\n",
    "test_path = '../data/test.csv'\n",
    "df_test = pd.read_csv(test_path)\n",
    "df_test['pred_label'] = np.argmax(ens_rslt, axis=1)\n",
    "idx_label = {0:'unrelated', 1:'agreed', 2:'disagreed'}\n",
    "df_test['pred_label'] = df_test['pred_label'].apply(lambda x: idx_label[x])\n",
    "\n",
    "df_test[['id', 'pred_label']].rename(columns={'id':'Id','pred_label':'Category'}).to_csv(submission_ensemble_path, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
